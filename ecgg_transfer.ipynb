{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFhi7QVJIMYQ",
        "outputId": "5b86700d-b8d7-405d-f01e-25d0ef5565b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. ADIM: KURULUM VE DRİVE BAĞLANTISI\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Drive Bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Gerekli kütüphaneyi kur (MIT-BIH okumak için)\n",
        "!pip install -q wfdb\n",
        "\n",
        "import wfdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUa9qT5NRXFi",
        "outputId": "b9cdb73c-3265-438f-c3d3-a852fbe99af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MIT-BIH veriseti zaten Drive'da mevcut.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 2. ADIM: VERİ İNDİRME (Senin düzenin)\n",
        "# ==========================================\n",
        "# Veriyi senin klasörüne indiriyoruz (zaten varsa indirmez)\n",
        "data_dir = \"/content/drive/MyDrive/mitdb\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Veri setini kontrol et, yoksa indir\n",
        "if len(os.listdir(data_dir)) < 10:\n",
        "    print(\"MIT-BIH veriseti indiriliyor...\")\n",
        "    !wget -q -r -N -c -np https://physionet.org/files/mitdb/1.0.0/ -P /content/\n",
        "    !cp -r /content/physionet.org/files/mitdb/1.0.0/* \"{data_dir}/\"\n",
        "    print(\"İndirme tamamlandı.\")\n",
        "else:\n",
        "    print(\"MIT-BIH veriseti zaten Drive'da mevcut.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F79oQsN-RZpq",
        "outputId": "4f690b8b-9cc0-4796-984a-cbe76d1db9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RR aralıkları ve semboller çekiliyor...\n",
            "Toplam sekans: 108638\n",
            "Sembol dağılımı: {np.str_('/'): np.int64(6981), np.str_('A'): np.int64(2526), np.str_('E'): np.int64(104), np.str_('F'): np.int64(800), np.str_('J'): np.int64(83), np.str_('L'): np.int64(8038), np.str_('N'): np.int64(74584), np.str_('Q'): np.int64(29), np.str_('R'): np.int64(7092), np.str_('S'): np.int64(2), np.str_('V'): np.int64(7036), np.str_('a'): np.int64(149), np.str_('e'): np.int64(16), np.str_('f'): np.int64(976), np.str_('j'): np.int64(222)}\n",
            "AAMI sınıf dağılımı: {'N': 89952, 'S': 2760, 'V': 7140, 'F': 800, 'Q': 7986}\n",
            "Dengelenmiş binary veri: 37372 örnek\n",
            "Şekiller ->\n",
            "Multi-class train: (86910, 10, 1) val: (21728, 10, 1)\n",
            "Binary train: (29897, 10, 1) test: (7475, 10, 1)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 3. ADIM: RR ARALIKLARI + ETİKETLER (MULTI-CLASS + BINARY)\n",
        "# ==========================================\n",
        "# Multi-class ön-eğitim için AAMI benzeri etiketleme, ardından binary fine-tune\n",
        "\n",
        "NORMAL_SYMBOLS = ['N', 'L', 'R', 'e', 'j']\n",
        "AAMI_MAP = {\n",
        "    'N': 'N', 'L': 'N', 'R': 'N', 'e': 'N', 'j': 'N',\n",
        "    'A': 'S', 'a': 'S', 'J': 'S', 'S': 'S',\n",
        "    'V': 'V', 'E': 'V',\n",
        "    'F': 'F',\n",
        "    '/': 'Q', 'f': 'Q', 'Q': 'Q'\n",
        "}\n",
        "AAMI_LABELS = {'N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4}\n",
        "ALLOWED_SYMBOLS = set(AAMI_MAP.keys())\n",
        "\n",
        "\n",
        "def load_rr_sequences(records, seq_len=10):\n",
        "    X_all = []\n",
        "    y_symbols = []\n",
        "    print(\"RR aralıkları ve semboller çekiliyor...\")\n",
        "    for record in records:\n",
        "        try:\n",
        "            ann = wfdb.rdann(f\"{data_dir}/{record}\", 'atr')\n",
        "            rr_intervals = np.diff(ann.sample) / 360.0\n",
        "            symbols = np.array(ann.symbol[1:])\n",
        "\n",
        "            min_len = min(len(rr_intervals), len(symbols))\n",
        "            rr_intervals = rr_intervals[:min_len]\n",
        "            symbols = symbols[:min_len]\n",
        "\n",
        "            valid = (rr_intervals > 0.2) & (rr_intervals < 2.0)\n",
        "            rr_intervals = rr_intervals[valid]\n",
        "            symbols = symbols[valid]\n",
        "\n",
        "            for i in range(len(rr_intervals) - seq_len):\n",
        "                sequence = rr_intervals[i : i + seq_len]\n",
        "                target_symbol = symbols[i + seq_len]\n",
        "                if target_symbol not in ALLOWED_SYMBOLS:\n",
        "                    continue\n",
        "                X_all.append(sequence)\n",
        "                y_symbols.append(target_symbol)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return np.array(X_all), np.array(y_symbols)\n",
        "\n",
        "\n",
        "# Kayıt listesi\n",
        "all_records = [f.replace('.dat', '') for f in os.listdir(data_dir) if f.endswith('.dat')]\n",
        "selected_records = all_records  # tamamını kullan\n",
        "\n",
        "X_seq, y_symbols = load_rr_sequences(selected_records, seq_len=10)\n",
        "print(f\"Toplam sekans: {len(X_seq)}\")\n",
        "unique, counts = np.unique(y_symbols, return_counts=True)\n",
        "print(\"Sembol dağılımı:\", dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "# --- MULTI-CLASS (AAMI) ---\n",
        "def to_aami_id(sym):\n",
        "    cls = AAMI_MAP.get(sym)\n",
        "    if cls is None:\n",
        "        return None\n",
        "    return AAMI_LABELS[cls]\n",
        "\n",
        "\n",
        "X_multi, y_multi = [], []\n",
        "for seq, sym in zip(X_seq, y_symbols):\n",
        "    cls_id = to_aami_id(sym)\n",
        "    if cls_id is not None:\n",
        "        X_multi.append(seq)\n",
        "        y_multi.append(cls_id)\n",
        "X_multi = np.array(X_multi)\n",
        "y_multi = np.array(y_multi)\n",
        "print(\"AAMI sınıf dağılımı:\", {k: int(np.sum(y_multi == v)) for k, v in AAMI_LABELS.items()})\n",
        "\n",
        "\n",
        "# --- BINARY (\n",
        "# =0, Aritmi=1) ---\n",
        "y_binary = np.array([0 if s in NORMAL_SYMBOLS else 1 for s in y_symbols])\n",
        "X_binary = X_seq\n",
        "\n",
        "arr_mask = y_binary == 1\n",
        "norm_mask = y_binary == 0\n",
        "arr_count = int(np.sum(arr_mask))\n",
        "if arr_count == 0:\n",
        "    raise ValueError(\"Aritmi örneği bulunamadı, veri filtresini kontrol et.\")\n",
        "\n",
        "X_norm_down = resample(X_binary[norm_mask], replace=False, n_samples=arr_count, random_state=42)\n",
        "y_norm_down = np.zeros(arr_count)\n",
        "X_balanced = np.concatenate([X_norm_down, X_binary[arr_mask]])\n",
        "y_balanced = np.concatenate([y_norm_down, np.ones(arr_count)])\n",
        "\n",
        "print(f\"Dengelenmiş binary veri: {len(X_balanced)} örnek\")\n",
        "\n",
        "\n",
        "# Eğitim/Test Ayırma\n",
        "Xmc_train, Xmc_val, ymc_train, ymc_val = train_test_split(\n",
        "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
        ")\n",
        "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
        "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "# Model giriş formatı: [örnek, zaman, özellik]\n",
        "Xmc_train = Xmc_train.reshape((-1, 10, 1))\n",
        "Xmc_val = Xmc_val.reshape((-1, 10, 1))\n",
        "Xmc_full = X_multi.reshape((-1, 10, 1))\n",
        "Xb_train = Xb_train.reshape((-1, 10, 1))\n",
        "Xb_test = Xb_test.reshape((-1, 10, 1))\n",
        "\n",
        "print(\"Şekiller ->\")\n",
        "print(\"Multi-class train:\", Xmc_train.shape, \"val:\", Xmc_val.shape)\n",
        "print(\"Binary train:\", Xb_train.shape, \"test:\", Xb_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbHfrdiXRcla",
        "outputId": "e3fcb6a5-e2c4-4c4c-e640-887ce5cc4858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CNN backbone multi-class ön-eğitimi başlıyor...\n",
            "Epoch 1/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8208 - loss: 0.5369 - val_accuracy: 0.8425 - val_loss: 0.4277\n",
            "Epoch 2/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.4308 - val_accuracy: 0.8610 - val_loss: 0.3883\n",
            "Epoch 3/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.4080 - val_accuracy: 0.8499 - val_loss: 0.5111\n",
            "Epoch 4/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.3900 - val_accuracy: 0.8508 - val_loss: 0.3903\n",
            "Epoch 5/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3818 - val_accuracy: 0.8502 - val_loss: 0.4088\n",
            "Epoch 6/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3747 - val_accuracy: 0.8472 - val_loss: 0.5184\n",
            "Epoch 7/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.3663 - val_accuracy: 0.8635 - val_loss: 0.3713\n",
            "Epoch 8/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3612 - val_accuracy: 0.8550 - val_loss: 0.5897\n",
            "Epoch 9/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8801 - loss: 0.3530 - val_accuracy: 0.8889 - val_loss: 0.3393\n",
            "Epoch 10/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.3548 - val_accuracy: 0.8686 - val_loss: 0.3540\n",
            "Epoch 11/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3500 - val_accuracy: 0.8880 - val_loss: 0.3356\n",
            "Epoch 12/12\n",
            "\u001b[1m1358/1358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.3451 - val_accuracy: 0.8681 - val_loss: 0.3781\n",
            "Backbone ağırlıkları kaydedildi: /content/drive/MyDrive/mitdb/cnn_rr_backbone.weights.h5\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 4. ADIM: CNN BACKBONE ÖN-EĞİTİMİ (MULTI-CLASS)\n",
        "# ==========================================\n",
        "\n",
        "def create_cnn_backbone(input_shape=(10, 1)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv1D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    return Model(inputs, x, name=\"rr_cnn_backbone\")\n",
        "\n",
        "\n",
        "def build_multiclass_model(backbone, num_classes):\n",
        "    x = backbone.output\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(backbone.input, outputs, name=\"rr_cnn_multiclass\")\n",
        "\n",
        "\n",
        "backbone = create_cnn_backbone(input_shape=(10, 1))\n",
        "mc_model = build_multiclass_model(backbone, num_classes=len(AAMI_LABELS))\n",
        "\n",
        "mc_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nCNN backbone multi-class ön-eğitimi başlıyor...\")\n",
        "history_mc = mc_model.fit(\n",
        "    Xmc_train,\n",
        "    ymc_train,\n",
        "    validation_data=(Xmc_val, ymc_val),\n",
        "    epochs=12,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "backbone_weights_path = '/content/drive/MyDrive/mitdb/cnn_rr_backbone.weights.h5'\n",
        "backbone.save_weights(backbone_weights_path)\n",
        "print(f\"Backbone ağırlıkları kaydedildi: {backbone_weights_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExQ_GOeRel5",
        "outputId": "a4f50f23-3c1c-4e32-c49d-340111bc0850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transfer learning (backbone donmuş) başlıyor...\n",
            "Epoch 1/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7203 - loss: 0.5486 - val_accuracy: 0.7813 - val_loss: 0.4616\n",
            "Epoch 2/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7846 - loss: 0.4608 - val_accuracy: 0.7946 - val_loss: 0.4396\n",
            "Epoch 3/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4359 - val_accuracy: 0.7969 - val_loss: 0.4308\n",
            "Epoch 4/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4309 - val_accuracy: 0.7980 - val_loss: 0.4237\n",
            "Epoch 5/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4223 - val_accuracy: 0.8047 - val_loss: 0.4197\n",
            "Epoch 6/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.4149 - val_accuracy: 0.8103 - val_loss: 0.4149\n",
            "Epoch 7/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4120 - val_accuracy: 0.8123 - val_loss: 0.4120\n",
            "Epoch 8/8\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.4143 - val_accuracy: 0.8135 - val_loss: 0.4084\n",
            "\n",
            "İnce ayar (üst conv katmanları açık)...\n",
            "Epoch 1/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8021 - loss: 0.4303 - val_accuracy: 0.8112 - val_loss: 0.4148\n",
            "Epoch 2/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.4184 - val_accuracy: 0.8108 - val_loss: 0.4119\n",
            "Epoch 3/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4154 - val_accuracy: 0.8126 - val_loss: 0.4102\n",
            "Epoch 4/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4136 - val_accuracy: 0.8102 - val_loss: 0.4101\n",
            "Epoch 5/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4096 - val_accuracy: 0.8136 - val_loss: 0.4089\n",
            "Epoch 6/6\n",
            "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4157 - val_accuracy: 0.8131 - val_loss: 0.4085\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 5. ADIM: TRANSFER LEARNING (BINARY FINE-TUNE)\n",
        "# ==========================================\n",
        "# Backbone'u yeniden kur, ağırlıkları yükle ve donmuş halde binary kafa eğit.\n",
        "\n",
        "backbone_ft = create_cnn_backbone(input_shape=(10, 1))\n",
        "backbone_ft.load_weights(backbone_weights_path)\n",
        "\n",
        "for layer in backbone_ft.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = backbone_ft.output\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "binary_output = layers.Dense(1, activation='sigmoid')(x)\n",
        "transfer_model = Model(backbone_ft.input, binary_output, name=\"rr_cnn_transfer\")\n",
        "\n",
        "transfer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "print(\"\\nTransfer learning (backbone donmuş) başlıyor...\")\n",
        "history_frozen = transfer_model.fit(\n",
        "    Xb_train,\n",
        "    yb_train,\n",
        "    validation_data=(Xb_test, yb_test),\n",
        "    epochs=8,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Üst katmanları açıp daha düşük LR ile fine-tune\n",
        "for layer in backbone_ft.layers[-2:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "transfer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "print(\"\\nİnce ayar (üst conv katmanları açık)...\")\n",
        "history_unfrozen = transfer_model.fit(\n",
        "    Xb_train,\n",
        "    yb_train,\n",
        "    validation_data=(Xb_test, yb_test),\n",
        "    epochs=6,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00bcc181",
        "outputId": "6d3e9d77-4946-4f20-c769-697068f0d862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Model Performans Raporu (Transfer):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.81      0.83      0.82      3738\n",
            "      Aritmi       0.82      0.80      0.81      3737\n",
            "\n",
            "    accuracy                           0.81      7475\n",
            "   macro avg       0.81      0.81      0.81      7475\n",
            "weighted avg       0.81      0.81      0.81      7475\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3086  652]\n",
            " [ 745 2992]]\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 6. ADIM: DEĞERLENDİRME\n",
        "# ==========================================\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred_prob = transfer_model.predict(Xb_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nModel Performans Raporu (Transfer):\")\n",
        "print(classification_report(yb_test, y_pred, target_names=['Normal', 'Aritmi']))\n",
        "\n",
        "cm = confusion_matrix(yb_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67fce290"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Confusion Matrix'i görselleştirme\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Normal', 'Aritmi'], yticklabels=['Normal', 'Aritmi'])\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Tahmin Edilen Etiket')\n",
        "plt.ylabel('Gerçek Etiket')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4778e9a0",
        "outputId": "2099e332-6792-4ffa-e401-156908725500"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Transfer modeli kaydedildi: /content/drive/MyDrive/mitdb/cnn_rr_arrhythmia_transfer.h5\n",
            "Backbone ağırlıkları: /content/drive/MyDrive/mitdb/cnn_rr_backbone.weights.h5\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 7. ADIM: MODELİ KAYDETME\n",
        "# ==========================================\n",
        "final_path = '/content/drive/MyDrive/mitdb/cnn_rr_arrhythmia_transfer.h5'\n",
        "transfer_model.save(final_path)\n",
        "print(f\"\\n✅ Transfer modeli kaydedildi: {final_path}\")\n",
        "print(f\"Backbone ağırlıkları: {backbone_weights_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
